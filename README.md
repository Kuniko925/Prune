<p align="left"> </p>
<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License: MIT"></a>
<a href="https://standardjs.com"><img src="https://img.shields.io/badge/code_style-standard-brightgreen.svg" alt="Standard - \Python Style Guide"></a>

# Enhancing Fairness in Skin Lesion Classification for Medical Diagnosis Using Prune Learning

Recent advances in deep learning have significantly improved the accuracy of skin lesion classification models, supporting medical diagnoses and promoting equitable healthcare. However, concerns remain about potential biases related to skin color, which can impact diagnostic outcomes. Ensuring fairness is challenging due to difficulties in classifying skin tones, high computational demands, and the complexity of objectively verifying fairness, given the continuous and context-dependent nature of skin tone and the dependence of fairness conclusions on metric choice and subgroup representation. To address these challenges, we propose a fairness algorithm for skin lesion classification that overcomes the challenges associated with achieving diagnostic fairness across varying skin tones. By calculating the skewness of the feature map in the convolution layer of the Visual Geometry Group network (VGG) and the patches and the heads of the Vision Transformer (ViT), our method reduces unnecessary channels related to skin tone, focusing instead on the lesion area. Application on VGG11 and ViT-B16, showed improved fairness metrics by 15-20% on average while maintaining accuracy and F1-score within 0.01 of the baseline. Additionally, the method reduced model size by 16% for VGG11 and decreased memory footprint for ViT-B16, without requiring skin tone labels at inference. Thus, the approach lowers computational costs and mitigates bias without relying on conventional statistical methods. It potentially reduces model size while maintaining fairness, making it more practical for real-world applications.
